#!/usr/bin/env python3
"""
Cognitive Planning Example for VLA (Vision-Language-Action) System

This example demonstrates the cognitive planning component of the VLA system,
showing how Large Language Models (LLMs) can be used to interpret natural
language commands and generate structured action plans for humanoid robots.

The example covers:
1. Natural language understanding with OpenAI GPT
2. Action decomposition and planning
3. ROS 2 action message conversion
4. Plan validation and optimization

To run this example, you need:
1. OpenAI API key set in environment variable OPENAI_API_KEY
2. Required Python packages installed
3. Understanding of the VLA system architecture

Installation:
pip install openai python-dotenv

Usage:
python cognitive_planning.py
"""

import openai
import os
import sys
import json
import time
import argparse
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from datetime import datetime

# Configuration
ENV_VAR_NAME = "OPENAI_API_KEY"


@dataclass
class RobotAction:
    """
    Represents an individual action that can be executed by the robot
    """
    id: str
    action_type: str  # NAVIGATION, MANIPULATION, INTERACTION, SENSING, OTHER
    parameters: Dict[str, Any]
    priority: int  # 1-5, with 5 being highest
    timeout: float  # seconds
    preconditions: List[str]  # Conditions that must be met before execution
    postconditions: List[str]  # Expected state after execution
    dependencies: List[str]  # Other actions that must complete first


@dataclass
class ActionPlan:
    """
    Represents a sequence of robot actions generated by the cognitive planning system
    """
    id: str
    command_id: str
    actions: List[RobotAction]
    created_at: str
    estimated_duration: float  # seconds
    complexity_score: int  # 1-10
    status: str = "PLANNED"
    execution_log: Optional[List[Dict[str, str]]] = None


class CognitivePlanner:
    """
    Cognitive planning system using LLMs for natural language understanding and action planning
    """
    def __init__(self, api_key: str):
        openai.api_key = api_key
        self.model = "gpt-4-turbo"  # Use gpt-4-turbo for best performance
        self.command_history = []

    def plan_actions_from_command(
        self,
        command: str,
        robot_state: Dict[str, Any] = None,
        user_context: Dict[str, Any] = None
    ) -> ActionPlan:
        """
        Plan robot actions based on a natural language command
        """
        start_time = time.time()

        # Build system prompt with robot capabilities and constraints
        system_prompt = self._build_system_prompt(robot_state)

        # Build user prompt with command and context
        user_prompt = self._build_user_prompt(command, user_context)

        # Call OpenAI API with function calling to ensure structured output
        response = openai.ChatCompletion.create(
            model=self.model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.1,  # Low temperature for consistent, structured output
            functions=[
                {
                    "name": "generate_action_plan",
                    "description": "Generate a structured action plan for the robot",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "actions": {
                                "type": "array",
                                "items": {
                                    "type": "object",
                                    "properties": {
                                        "action_type": {
                                            "type": "string",
                                            "enum": ["NAVIGATION", "MANIPULATION", "INTERACTION", "SENSING", "OTHER"]
                                        },
                                        "parameters": {"type": "object"},
                                        "priority": {"type": "integer", "minimum": 1, "maximum": 5},
                                        "timeout": {"type": "number", "minimum": 0},
                                        "preconditions": {
                                            "type": "array",
                                            "items": {"type": "string"}
                                        },
                                        "postconditions": {
                                            "type": "array",
                                            "items": {"type": "string"}
                                        },
                                        "dependencies": {
                                            "type": "array",
                                            "items": {"type": "string"}
                                        }
                                    },
                                    "required": ["action_type", "parameters"]
                                }
                            },
                            "estimated_duration": {"type": "number", "minimum": 0},
                            "complexity_score": {"type": "integer", "minimum": 1, "maximum": 10}
                        },
                        "required": ["actions", "estimated_duration", "complexity_score"]
                    }
                }
            ],
            function_call={"name": "generate_action_plan"}
        )

        # Parse the function call result
        function_args = json.loads(response.choices[0].message.function_call.arguments)

        # Convert the result to RobotAction objects
        robot_actions = []
        for i, action_data in enumerate(function_args["actions"]):
            robot_action = RobotAction(
                id=f"action_{i}",
                action_type=action_data["action_type"],
                parameters=action_data.get("parameters", {}),
                priority=action_data.get("priority", 3),
                timeout=action_data.get("timeout", 30.0),
                preconditions=action_data.get("preconditions", []),
                postconditions=action_data.get("postconditions", []),
                dependencies=action_data.get("dependencies", [])
            )
            robot_actions.append(robot_action)

        # Create and return the ActionPlan
        action_plan = ActionPlan(
            id=f"plan_{int(time.time())}",
            command_id=f"cmd_{int(time.time())}",
            actions=robot_actions,
            created_at=str(datetime.now()),
            estimated_duration=function_args["estimated_duration"],
            complexity_score=function_args["complexity_score"]
        )

        # Add to command history
        self.command_history.append({
            "command": command,
            "plan_id": action_plan.id,
            "timestamp": datetime.now(),
            "complexity": action_plan.complexity_score
        })

        processing_time = time.time() - start_time
        print(f"Cognitive planning completed in {processing_time:.2f} seconds")
        print(f"Generated {len(robot_actions)} actions with complexity {action_plan.complexity_score}/10")

        return action_plan

    def _build_system_prompt(self, robot_state: Dict[str, Any]) -> str:
        """
        Build the system prompt with robot capabilities and constraints
        """
        capabilities = [
            "NAVIGATION: move to locations, follow paths, avoid obstacles",
            "MANIPULATION: pick up objects, place objects, open/close containers",
            "INTERACTION: speak, gesture, respond to humans, facial expressions",
            "SENSING: detect objects, recognize faces, measure distances, environmental awareness"
        ]

        constraints = [
            "Robot cannot go through walls or obstacles",
            "Robot cannot manipulate objects beyond its reach or weight capacity",
            "Robot must maintain balance during actions",
            "Robot should avoid unsafe situations",
            "Robot operates within known map boundaries"
        ]

        system_prompt = f"""
        You are a cognitive planning system for a humanoid robot. Your role is to interpret natural language commands
        and generate detailed, structured action plans that the robot can execute safely and effectively.

        Robot Capabilities:
        {chr(10).join(capabilities)}

        Robot Constraints:
        {chr(10).join(constraints)}

        Current Robot State:
        {json.dumps(robot_state, indent=2) if robot_state else 'Unknown - assume normal operational state'}

        Generate action plans that:
        1. Are feasible given the robot's capabilities
        2. Respect the robot's physical constraints
        3. Account for the current environment and state
        4. Include appropriate preconditions and postconditions
        5. Sequence actions logically with proper dependencies
        6. Prioritize safety and efficiency
        7. Break down complex commands into simple, executable actions

        Return the plan in the requested structured format.
        """

        return system_prompt

    def _build_user_prompt(self, command: str, user_context: Dict[str, Any]) -> str:
        """
        Build the user prompt with the command and context
        """
        context_str = f"User Context: {json.dumps(user_context, indent=2)}" if user_context else "No user context provided"

        user_prompt = f"""
        {context_str}

        Command: "{command}"

        Please generate a detailed action plan for the robot to execute this command.
        Break down complex commands into simple, executable actions.
        Consider the robot's current state and environment when planning.
        Ensure actions are sequenced logically and safely.
        """

        return user_prompt

    def validate_plan(self, plan: ActionPlan, robot_state: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        Validate an action plan for feasibility and safety
        """
        validation_results = {
            "is_valid": True,
            "issues": [],
            "warnings": [],
            "suggestions": []
        }

        # Check for basic issues
        if len(plan.actions) == 0:
            validation_results["is_valid"] = False
            validation_results["issues"].append("Plan contains no actions")
            return validation_results

        # Check for circular dependencies
        if self._has_circular_dependencies(plan.actions):
            validation_results["is_valid"] = False
            validation_results["issues"].append("Plan contains circular dependencies")

        # Check action feasibility based on robot state
        if robot_state:
            for i, action in enumerate(plan.actions):
                if not self._is_action_feasible(action, robot_state):
                    validation_results["warnings"].append(
                        f"Action {i} may not be feasible with current robot state: {action.action_type}"
                    )

        # Check for potentially unsafe action sequences
        for i in range(len(plan.actions) - 1):
            current_action = plan.actions[i]
            next_action = plan.actions[i + 1]

            # Check for unsafe transitions (e.g., navigating while carrying object without verification)
            if (current_action.action_type == "MANIPULATION" and
                "pick_up" in str(current_action.parameters) and
                next_action.action_type == "NAVIGATION"):
                validation_results["warnings"].append(
                    f"Potential safety issue: Navigating after picking up object without verification at step {i + 1}"
                )

        return validation_results

    def _has_circular_dependencies(self, actions: List[RobotAction]) -> bool:
        """
        Check if there are circular dependencies in the action plan
        """
        # Build dependency graph
        graph = {}
        for action in actions:
            graph[action.id] = set(action.dependencies)

        # Check for cycles using DFS
        visiting = set()
        visited = set()

        def has_cycle(node):
            if node in visited:
                return False
            if node in visiting:
                return True

            visiting.add(node)
            for dependency in graph.get(node, []):
                if has_cycle(dependency):
                    return True
            visiting.remove(node)
            visited.add(node)
            return False

        for action in actions:
            if has_cycle(action.id):
                return True

        return False

    def _is_action_feasible(self, action: RobotAction, robot_state: Dict[str, Any]) -> bool:
        """
        Check if an action is feasible given the robot state
        """
        # This is a simplified check - in practice, this would be more sophisticated
        if action.action_type == "MANIPULATION":
            if "pick_up" in str(action.parameters):
                # Check if gripper is free
                return robot_state.get("gripper_status") == "free"
        elif action.action_type == "NAVIGATION":
            # Check if navigation is enabled
            return robot_state.get("navigation_enabled", True)

        return True  # Default to feasible if no specific checks


class ROS2ActionConverter:
    """
    Converts planned actions to ROS 2 action messages
    """
    def __init__(self):
        self.action_type_mapping = {
            "NAVIGATION": self._convert_navigation_action,
            "MANIPULATION": self._convert_manipulation_action,
            "INTERACTION": self._convert_interaction_action,
            "SENSING": self._convert_sensing_action
        }

    def convert_to_ros2_action(self, robot_action: RobotAction) -> Dict[str, Any]:
        """
        Convert a RobotAction to a ROS 2 action message structure
        """
        converter = self.action_type_mapping.get(robot_action.action_type)
        if not converter:
            raise ValueError(f"Unknown action type: {robot_action.action_type}")

        return converter(robot_action)

    def _convert_navigation_action(self, action: RobotAction) -> Dict[str, Any]:
        """
        Convert navigation action to ROS 2 NavigateToPose action
        """
        target_location = action.parameters.get("target_location", "")

        # In a real implementation, this would interface with a map system
        # For this example, we'll use a simple location mapping
        location_coordinates = {
            "kitchen": {"x": 5.0, "y": 3.0, "z": 0.0, "yaw": 0.0},
            "living_room": {"x": 0.0, "y": 0.0, "z": 0.0, "yaw": 1.57},
            "bedroom": {"x": -3.0, "y": 2.0, "z": 0.0, "yaw": 3.14},
            "dining_room": {"x": 2.0, "y": -2.0, "z": 0.0, "yaw": -1.57}
        }.get(target_location, {"x": 0.0, "y": 0.0, "z": 0.0, "yaw": 0.0})

        ros2_action = {
            "action_type": "NavigateToPose",
            "goal": {
                "pose": {
                    "position": {
                        "x": location_coordinates["x"],
                        "y": location_coordinates["y"],
                        "z": location_coordinates["z"]
                    },
                    "orientation": {
                        "x": 0.0,
                        "y": 0.0,
                        "z": location_coordinates["yaw"],
                        "w": 1.0
                    }
                },
                "behavior_tree": "default_nav_tree"
            },
            "timeout": action.timeout,
            "action_id": action.id
        }

        return ros2_action

    def _convert_manipulation_action(self, action: RobotAction) -> Dict[str, Any]:
        """
        Convert manipulation action to ROS 2 manipulation action
        """
        manip_action = action.parameters.get("action", "")
        object_name = action.parameters.get("object", "")

        if manip_action in ["pick_up", "grasp"]:
            ros2_action = {
                "action_type": "PickObject",
                "goal": {
                    "object_name": object_name,
                    "arm_name": "right_arm",
                    "grasp_pose": {
                        "position": {"x": 0.1, "y": 0.0, "z": 0.1},
                        "orientation": {"x": 0.0, "y": 0.707, "z": 0.0, "w": 0.707}
                    }
                },
                "timeout": action.timeout,
                "action_id": action.id
            }
        elif manip_action in ["place_down", "place"]:
            target_location = action.parameters.get("target_location", "default")
            ros2_action = {
                "action_type": "PlaceObject",
                "goal": {
                    "object_name": object_name,
                    "place_pose": {
                        "position": {"x": 0.5, "y": 0.0, "z": 0.8},
                        "orientation": {"x": 0.0, "y": 0.0, "z": 0.0, "w": 1.0}
                    }
                },
                "timeout": action.timeout,
                "action_id": action.id
            }
        else:
            ros2_action = {
                "action_type": "GenericManipulation",
                "goal": {
                    "manipulation_type": manip_action,
                    "object_name": object_name
                },
                "timeout": action.timeout,
                "action_id": action.id
            }

        return ros2_action

    def _convert_interaction_action(self, action: RobotAction) -> Dict[str, Any]:
        """
        Convert interaction action to ROS 2 interaction action
        """
        interaction_type = action.parameters.get("type", "speak")

        if interaction_type == "speak":
            ros2_action = {
                "action_type": "Speak",
                "goal": {
                    "text": action.parameters.get("text", "Hello"),
                    "voice_parameters": {
                        "volume": action.parameters.get("volume", 0.8),
                        "rate": action.parameters.get("rate", 1.0)
                    }
                },
                "timeout": action.timeout,
                "action_id": action.id
            }
        elif interaction_type == "gesture":
            ros2_action = {
                "action_type": "PerformGesture",
                "goal": {
                    "gesture_name": action.parameters.get("gesture", "wave"),
                    "speed": action.parameters.get("speed", 1.0)
                },
                "timeout": action.timeout,
                "action_id": action.id
            }
        else:
            ros2_action = {
                "action_type": "GenericInteraction",
                "goal": {
                    "interaction_type": interaction_type,
                    "parameters": action.parameters
                },
                "timeout": action.timeout,
                "action_id": action.id
            }

        return ros2_action

    def _convert_sensing_action(self, action: RobotAction) -> Dict[str, Any]:
        """
        Convert sensing action to ROS 2 sensing action
        """
        sensing_type = action.parameters.get("type", "detect_objects")

        ros2_action = {
            "action_type": "SensorAction",
            "goal": {
                "sensor_type": sensing_type,
                "parameters": action.parameters
            },
            "timeout": action.timeout,
            "action_id": action.id
        }

        return ros2_action


def main():
    """
    Main function to demonstrate cognitive planning capabilities
    """
    parser = argparse.ArgumentParser(description="Cognitive Planning Example for VLA System")
    parser.add_argument(
        "--command",
        type=str,
        help="Direct command to process",
        default="Go to the kitchen and bring me a cup from the table"
    )
    parser.add_argument(
        "--demo-mode",
        action="store_true",
        help="Run through multiple demo commands"
    )

    args = parser.parse_args()

    # Check for API key
    api_key = os.getenv(ENV_VAR_NAME)
    if not api_key:
        print(f"Error: {ENV_VAR_NAME} environment variable not set.")
        print("Please set your OpenAI API key as an environment variable.")
        print("Example: export OPENAI_API_KEY='your-api-key-here'")
        return 1

    # Initialize cognitive planner
    planner = CognitivePlanner(api_key)

    # Example robot state (in a real system, this would come from ROS 2)
    robot_state = {
        "robot_operational": True,
        "gripper_status": "free",  # or "holding_object"
        "navigation_enabled": True,
        "current_location": "living_room",
        "battery_level": 0.85,
        "connected_devices": ["lidar", "cameras", "microphones", "speakers"]
    }

    # Example user context
    user_context = {
        "user_id": "user_123",
        "preference_language": "en",
        "familiar_locations": ["kitchen", "living_room", "bedroom"],
        "preferred_interaction_style": "polite"
    }

    print("=" * 70)
    print("VLA Cognitive Planning Example")
    print("=" * 70)
    print(f"Robot State: {json.dumps(robot_state, indent=2)}")
    print(f"User Context: {json.dumps(user_context, indent=2)}")
    print("-" * 70)

    if args.demo_mode:
        # Run through multiple demo commands
        demo_commands = [
            "Go to the kitchen and bring me a cup from the table",
            "Please move the red book from the table to the shelf",
            "Introduce yourself to the person in the living room",
            "Find my keys and bring them to me",
            "Turn on the lights in the bedroom"
        ]

        for i, command in enumerate(demo_commands):
            print(f"\nDemo Command {i + 1}: {command}")
            print("-" * 40)

            # Generate action plan
            action_plan = planner.plan_actions_from_command(
                command=command,
                robot_state=robot_state,
                user_context=user_context
            )

            # Validate the plan
            validation = planner.validate_plan(action_plan, robot_state)
            print(f"Plan Validation: {'VALID' if validation['is_valid'] else 'INVALID'}")
            if validation['issues']:
                print(f"Issues: {validation['issues']}")
            if validation['warnings']:
                print(f"WARNINGS: {validation['warnings']}")

            # Convert to ROS 2 actions
            ros2_converter = ROS2ActionConverter()
            ros2_actions = []
            for robot_action in action_plan.actions:
                try:
                    ros2_action = ros2_converter.convert_to_ros2_action(robot_action)
                    ros2_actions.append(ros2_action)
                except Exception as e:
                    print(f"Error converting action {robot_action.id}: {str(e)}")

            # Display results
            print(f"Generated {len(action_plan.actions)} planned actions")
            print(f"Estimated duration: {action_plan.estimated_duration:.2f} seconds")
            print(f"Complexity score: {action_plan.complexity_score}/10")

            if len(ros2_actions) > 0:
                print(f"Converted to {len(ros2_actions)} ROS 2 action messages")
                print("Sample ROS 2 action:", json.dumps(ros2_actions[0], indent=2))

    else:
        # Process single command
        command = args.command
        print(f"Processing Command: {command}")
        print("-" * 40)

        # Generate action plan
        action_plan = planner.plan_actions_from_command(
            command=command,
            robot_state=robot_state,
            user_context=user_context
        )

        # Validate the plan
        validation = planner.validate_plan(action_plan, robot_state)
        print(f"Plan Validation: {'VALID' if validation['is_valid'] else 'INVALID'}")
        if validation['issues']:
            print(f"Issues: {validation['issues']}")
        if validation['warnings']:
            print(f"WARNINGS: {validation['warnings']}")

        # Convert to ROS 2 actions
        ros2_converter = ROS2ActionConverter()
        ros2_actions = []
        for robot_action in action_plan.actions:
            try:
                ros2_action = ros2_converter.convert_to_ros2_action(robot_action)
                ros2_actions.append(ros2_action)
            except Exception as e:
                print(f"Error converting action {robot_action.id}: {str(e)}")

        # Display detailed results
        print(f"\nAction Plan Details:")
        print(f"  Plan ID: {action_plan.id}")
        print(f"  Command ID: {action_plan.command_id}")
        print(f"  Number of Actions: {len(action_plan.actions)}")
        print(f"  Estimated Duration: {action_plan.estimated_duration:.2f} seconds")
        print(f"  Complexity Score: {action_plan.complexity_score}/10")
        print(f"  Status: {action_plan.status}")

        print(f"\nPlanned Actions:")
        for i, action in enumerate(action_plan.actions):
            print(f"  {i+1}. {action.action_type}: {action.parameters}")
            print(f"     Priority: {action.priority}, Timeout: {action.timeout}s")
            if action.preconditions:
                print(f"     Preconditions: {action.preconditions}")
            if action.postconditions:
                print(f"     Postconditions: {action.postconditions}")
            if action.dependencies:
                print(f"     Dependencies: {action.dependencies}")

        if ros2_actions:
            print(f"\nROS 2 Action Messages:")
            for i, ros2_action in enumerate(ros2_actions):
                print(f"  {i+1}. {ros2_action['action_type']} - ID: {ros2_action['action_id']}")

    # Print summary
    print("\n" + "=" * 70)
    print("Cognitive Planning Session Summary:")
    print(f"  Total commands processed: {len(planner.command_history)}")
    if planner.command_history:
        avg_complexity = sum(item['complexity'] for item in planner.command_history) / len(planner.command_history)
        print(f"  Average complexity: {avg_complexity:.2f}/10")
    print("=" * 70)

    return 0


if __name__ == "__main__":
    sys.exit(main())